{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring complexity\n",
    "\n",
    "Hi guys ! Through this notebook, I'll take you with me in my journey to explore the potential of complexity measures in realtime processing of EEG signals. \n",
    "\n",
    "\n",
    "Because the goal of this notebook is only  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from mne.io import read_raw_fif\n",
    "import mne\n",
    "from brainpipe.feature import power\n",
    "import numpy as np\n",
    "import neurokit\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.\n",
    "# Fetch time series data from any file whatsoever\n",
    "# Must be at least 30 seconds at 250Hz\n",
    "\n",
    "raw_rs = read_raw_fif('/home/hyruuk/mne_data/MNE-brainstorm-data/bst_raw/SA04_01_preprocessed.fif.gz', preload=True)\n",
    "raw_task = read_raw_fif('/home/hyruuk/mne_data/MNE-brainstorm-data/bst_raw/SA04_02_preprocessed.fif.gz', preload=True)\n",
    "sfreq = raw_rs.info['sfreq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def slice_into_epochs(raw, n_timepoints=3000):\n",
    "    # Average all channels and slice into epochs\n",
    "    picks = mne.pick_types(raw.info, meg=True, eeg=False)\n",
    "    all_timeseries = np.mean(raw.get_data(picks=picks)[:,:], axis=0)\n",
    "    \n",
    "    xs = np.array([x for x in range(0, raw_rs.get_data(picks=picks).shape[1], 3000)])\n",
    "    eeg_timeseries = []\n",
    "    for x in xs:\n",
    "        start = x\n",
    "        stop = x + 3000\n",
    "        if stop < len(all_timeseries):\n",
    "            eeg_timeseries.append(all_timeseries[start:stop])\n",
    "    timeseries = np.array(eeg_timeseries)\n",
    "    return timeseries\n",
    "\n",
    "timeseries_rs = slice_into_epochs(raw_rs, n_timepoints=3000)\n",
    "timeseries_task = slice_into_epochs(raw_task, n_timepoints=3000)\n",
    "timeseries_rs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.\n",
    "# Compute hilbert using brainpipe\n",
    "def get_hilbert(data, freq=1):\n",
    "    # data = n_elec * n_timepoints\n",
    "    f = [[4, 8], [8, 12], [12, 30], [30,60]]\n",
    "    power_obj = power(sfreq, npts=data.shape[1], f=f, baseline=None, norm=None, method='hilbert', window=None, width=None, step=None, split=None, time=None)\n",
    "    power_vals = power_obj.get(data.T)[0].squeeze() # get power values across time\n",
    "    power_vals = power_vals[freq,:,:].T\n",
    "    return power_vals\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.\n",
    "# Compute complexity using neurokit\n",
    "eeg_timeseries = ep_wake[0,:] # We take only the first epoch\n",
    "\n",
    "start = time.time()\n",
    "comp = neurokit.complexity(eeg_timeseries)\n",
    "stop = time.time()\n",
    "print(\"duration of computation :\")\n",
    "print(stop-start)\n",
    "print(comp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Compare the Hurst and complexity values of pure sine, white, pink and brown noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from acoustics.generator import noise\n",
    "\n",
    "np.random.seed(0) \n",
    "fs = 100\n",
    "dur = 30\n",
    "\n",
    "\n",
    "\n",
    "# Let's do the same with simulated data ! \n",
    "\n",
    "# First we can generate a pure tone at a frequency of 10Hz\n",
    "samples = np.linspace(0, dur, dur * fs)\n",
    "n_samples = len(samples)\n",
    "freq = 0.1\n",
    "pure = np.sin(2 * np.pi * freq * samples)\n",
    "\n",
    "white_noise = noise(n_samples, color='white') # A good model for EEG signals can be... Sound signals !\n",
    "pink_noise = noise(n_samples, color='pink') # Both are complex time series with a wide spectral content.\n",
    "brown_noise = noise(n_samples, color='brown') # The acoustics toolbox will help us design various flavours of noise !\n",
    "blue_noise = noise(n_samples, color='blue')\n",
    "eeg_timeseries = ep_wake[0,:] # We take only the first epoch\n",
    "eeg_alphaEnv = get_hilbert(ep_wake, freq=1)[0,:]\n",
    "eeg_thetaEnv = get_hilbert(ep_wake, freq=0)[0,:]\n",
    "\n",
    "\n",
    "# Let's create a small plotting function to visualize the timeseries\n",
    "def timeseries_plot(sig, ax, title = None):\n",
    "    ax.plot(sig)\n",
    "    ax.set_xlabel('time (sample)', fontsize=12)\n",
    "    ax.set_ylabel('value', fontsize=12)\n",
    "    ax.set_title(title, fontsize=20)\n",
    "\n",
    "# Now we stack the signals in a list so we can plot them easily through a loop\n",
    "sigs = [blue_noise, white_noise, pink_noise, brown_noise, pure, eeg_timeseries, eeg_alphaEnv, eeg_thetaEnv]\n",
    "sig_names = ['Blue noise', 'White noise', 'Pink noise', 'Brown noise', 'Pure sine', 'EEG timeseries', 'EEG alpha', 'EEG theta']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(nrows=2, ncols=4, figsize=(20,10), constrained_layout=True)\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    timeseries_plot(sigs[i], ax, title=sig_names[i])\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wow dem curves looks great !\n",
    "\n",
    "But... How do I know these signals are really what they pretend to be ?\n",
    "\n",
    "Also, what are blue/white/pink/brown noises ?\n",
    "\n",
    "They all look blue to me..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The colors describe the spectral distribution of each kind of noise.\n",
    "# So, in order to understand their differences, we should look a their spectrum !\n",
    "# In white noise, all frequencies contribute equally.\n",
    "# In pink noise, the relationship between the amplitude and the frequency follows a power law (1/f).\n",
    "# Brown noise is similar to pink noise but follow a (1/fÂ²) power law.\n",
    "\n",
    "\n",
    "import scipy\n",
    "\n",
    "\n",
    "\n",
    "def spectrum_plot(sig, ax, title = None):\n",
    "    N = len(sig)\n",
    "    # sample spacing\n",
    "    T = 1.0 / sfreq\n",
    "    yf = scipy.fftpack.fft(sig)\n",
    "    xf = np.linspace(0.0, 1.0/(2.0*T), N/2) # The maths here are used to transform our fft\n",
    "    ax.plot(xf, 2.0/N * np.abs(yf[:N//2]))  # into an easily visualizable representation\n",
    "    ax.set_xlabel('Frequency (Hz)', fontsize=12)\n",
    "    ax.set_ylabel('Amplitude', fontsize=12)\n",
    "    ax.set_title(title, fontsize=20)\n",
    "\n",
    "    \n",
    "fig, axs = plt.subplots(nrows=2, ncols=4, figsize=(20,10), constrained_layout=True)\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    spectrum_plot(sigs[i], ax, title=sig_names[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See ? The spectrum of the EEG timeseries seems to fall somewhere between pink and brown noise. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Awesome, but now...\n",
    "\n",
    "... will you tell me what complexity means ? How do these flavours of noise differ in terms of Hurst exponent, Higuchi fractal dimension or SVD entropy ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's explore the complexity measures offered by NeuroKit !\n",
    "\n",
    "def complexity_plot(sigs, sig_names, met, ax):\n",
    "    comp_values = []\n",
    "    for i, sig in enumerate(sigs):\n",
    "        comp_values.append(comp_compute(sig, compute=met))\n",
    "    ax.bar(np.arange(len(comp_values)), comp_values)\n",
    "    ax.set_ylabel('Value', fontsize=12)\n",
    "    ax.set_xticks(np.arange(len(sig_names)))\n",
    "    ax.set_xticklabels(sig_names)\n",
    "    ax.set_title(met, fontsize=20)\n",
    "    return comp_values\n",
    "\n",
    "    \n",
    "fig, axs = plt.subplots(3,4,figsize=(20,10), constrained_layout=True)\n",
    "\n",
    "metrics = ['shannon', 'sampen', 'multiscale', 'spectral', 'svd', 'correlation', 'higushi', 'petrosian', 'fisher', 'hurst', 'dfa', 'lyap_e']\n",
    "\n",
    "sig_names_short = ['Bl', 'W', 'P', 'Br', 'sin', 'EEG', 'a', 't']\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    comp_values = complexity_plot(sigs, sig_names_short, metrics[i], ax)\n",
    "plt.savefig('comp_measures.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I remark that :\n",
    "- Sample and multiscale entropy didn't compute\n",
    "- Shannon entropy is largely the same for all signals, same for petrosian\n",
    "- EEG signals are often comprised somewhere between Pink and Brown noise\n",
    "- 0<H<0.5 means short term correlations (i.e., high frequencies), 0.5<H<1 means long term correlations (low frequencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, are these metrics able to discriminate between mental states ?\n",
    "\n",
    "- When applied on raw timeseries ?\n",
    "- When applied on power band envelope ?\n",
    "- What is the minimum time window required to keep this discriminant power ?\n",
    "- How fast is it to compute ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne.datasets import sleep_physionet\n",
    "dl_path = sleep_physionet.age.fetch_data(subjects=[0], recording=[1]) # Downloads the sleep dataset\n",
    "data_path = dl_path[0][0] # Get path of datafile\n",
    "annot_path = dl_path[0][1] # Get path of annotations (sleep stages info) file\n",
    "\n",
    "\n",
    "raw_data = mne.io.read_raw_edf(data_path) # Read datafile\n",
    "sfreq = raw_data.info['sfreq'] # We'll need to keep this for later\n",
    "annot = mne.read_annotations(annot_path) # Read sleep stages annotation file\n",
    "raw_data.set_annotations(annot, emit_warning=False) # Link annotations to data\n",
    "\n",
    "# With these files, MNE -wrongly- recognizes all channels as EEG.\n",
    "# So we need to tell it which channel isn't EEG\n",
    "mapping = {'EOG horizontal': 'eog',\n",
    "           'Resp oro-nasal': 'misc',\n",
    "           'EMG submental': 'misc',\n",
    "           'Temp rectal': 'misc',\n",
    "           'Event marker': 'misc'}\n",
    "raw_data.set_channel_types(mapping)\n",
    "picks = mne.pick_types(raw_data.info, meg=False, eeg=True) # keep EEG indices in picks\n",
    "\n",
    "\n",
    "# Segment data into epochs of different conditions (ex. wake vs sleep)\n",
    "## first declare some variables\n",
    "annotation_desc_2_event_id = {'Sleep stage W': 1,\n",
    "                              'Sleep stage 1': 2,\n",
    "                              'Sleep stage 2': 3,\n",
    "                              'Sleep stage 3': 4,\n",
    "                              'Sleep stage 4': 4,\n",
    "                              'Sleep stage R': 5}\n",
    "event_id = {'Sleep stage W': 1,\n",
    "            'Sleep stage 1': 2,\n",
    "            'Sleep stage 2': 3,\n",
    "            'Sleep stage 3/4': 4,\n",
    "            'Sleep stage R': 5}\n",
    "\n",
    "tmax = 30. - 1. / sfreq # define duration of an epoch, here we will take 30 seconds in order to reach 3000pts\n",
    "\n",
    "## find events from annotations file\n",
    "events, _ = mne.events_from_annotations(\n",
    "    raw_data, event_id=annotation_desc_2_event_id, chunk_duration=tmax)\n",
    "\n",
    "## segment datafile based on events\n",
    "epochs = mne.Epochs(raw=raw_data, events=events, event_id=event_id,\n",
    "                         tmin=0., tmax=tmax, baseline=None)\n",
    "\n",
    "## split epochs in the two conditions\n",
    "ep_wake = np.average(epochs['Sleep stage W'].get_data(picks=picks), axis=1) # Average across electrodes\n",
    "ep_sleep = np.average(epochs['Sleep stage 3/4'].get_data(picks=picks), axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_compute(data, verbose=False, compute='hurst'):\n",
    "    shannon, sampen, multiscale, spectral, svd, correlation, higushi, petrosian, fisher, hurst, dfa, lyap_r, lyap_e = False, False, False, False, False, False, False, False, False, False, False, False, False\n",
    "\n",
    "    if compute == 'shannon':\n",
    "        shannon = True\n",
    "    if compute == 'sampen':\n",
    "        sampen = True\n",
    "    if compute == 'multiscale':\n",
    "        multiscale = True\n",
    "    if compute == 'spectral': #### Maybe that huge wall can be improved\n",
    "        spectral = True\n",
    "    if compute == 'svd':\n",
    "        svd = True\n",
    "    if compute == 'correlation':\n",
    "        correlation = True\n",
    "    if compute == 'higushi':\n",
    "        higushi = True\n",
    "    if compute == 'petrosian':\n",
    "        petrosian = True\n",
    "    if compute == 'fisher':\n",
    "        fisher = True\n",
    "    if compute == 'hurst':\n",
    "        hurst = True\n",
    "    if compute == 'dfa':\n",
    "        dfa = True\n",
    "    if compute == 'lyap_r':\n",
    "        lyap_r = True\n",
    "    if compute == 'lyap_e':\n",
    "        lyap_e = True\n",
    "\n",
    "    start = time.time()\n",
    "    comp = neurokit.complexity(data, sampling_rate=sfreq, \n",
    "                               shannon=shannon, \n",
    "                               sampen=sampen, \n",
    "                               multiscale=multiscale, \n",
    "                               spectral=spectral, \n",
    "                               svd=svd, \n",
    "                               correlation=correlation, \n",
    "                               higushi=higushi, \n",
    "                               petrosian=petrosian, \n",
    "                               fisher=fisher, \n",
    "                               hurst=hurst, \n",
    "                               dfa=dfa, \n",
    "                               lyap_r=lyap_r, \n",
    "                               lyap_e=lyap_e, \n",
    "                               emb_dim=2, tolerance=\"default\", k_max=8, bands=None, tau=1)\n",
    "    stop = time.time()\n",
    "    \n",
    "    if verbose==True:\n",
    "        print(\"Computed in {} seconds\".format(stop-start))\n",
    "        print(comp)\n",
    "        \n",
    "    metric_name = [i for i in comp.keys()][0]\n",
    "    return comp[metric_name]\n",
    "\n",
    "\n",
    "def compute_A_vs_B(ep_cond1, ep_cond2, compute='hurst'):\n",
    "    n_epochs = np.min([ep_cond1.shape[0], ep_cond2.shape[0]])  # The maximum number of epochs we can compare is constrained by the number of sleep epochs\n",
    "    comp_cond1 = []\n",
    "    comp_cond2 = []\n",
    "    for epoch_id in range(n_epochs):\n",
    "        comp_cond1.append(comp_compute(ep_cond1[epoch_id,:], compute=compute))\n",
    "        comp_cond2.append(comp_compute(ep_cond2[epoch_id,:], compute=compute))\n",
    "    comp_cond1 = np.array(comp_cond1)\n",
    "    comp_cond2 = np.array(comp_cond2)\n",
    "    tval, pval = ttest_ind(comp_cond1, comp_cond2)\n",
    "    print('{} binomial pval with N={}, : {}'.format(compute, n_epochs, pval))\n",
    "    return comp_cond1, comp_cond2, pval, n_epochs\n",
    "\n",
    "\n",
    "def plot_A_vs_B(comp_cond1, comp_cond2, cond_names, pval, met, ax=None):\n",
    "    ######### Create a boxplot\n",
    "    \n",
    "    #### Create dataframe for Seaborn\n",
    "    values = np.hstack((comp_cond1, comp_cond2))\n",
    "    condition = np.hstack(([cond_names[0]]*len(comp_cond1), [cond_names[1]]*len(comp_cond2)))\n",
    "    d = {'Values': values, 'Condition': condition}\n",
    "    df = pd.DataFrame(data=d)\n",
    "    \n",
    "    if ax == None:\n",
    "        f, ax = plt.subplots(figsize=(7, 6))\n",
    "    \n",
    "    # Create boxes\n",
    "    sns.boxplot(x=\"Condition\", y=\"Values\", data=df,\n",
    "                whis=\"range\", ax=ax)\n",
    "    \n",
    "    if len(comp_cond1) >= 50: # If n_epochs > 50 we use a violinplot  \n",
    "        sns.violinplot(x=\"Condition\", y=\"Values\", data=df,\n",
    "                      size=2, linewidth=0.5, ax=ax, palette='vlag')\n",
    "    else: # Add in points to show each observation\n",
    "        sns.swarmplot(x=\"Condition\", y=\"Values\", data=df,\n",
    "              size=10, linewidth=0.5, ax=ax, palette='vlag')\n",
    "    \n",
    "    # Tweak the visual presentation\n",
    "    ax.xaxis.grid(True);\n",
    "    sns.despine(trim=True, left=True, ax=ax)\n",
    "    \n",
    "    # Add pvals in title\n",
    "    if pval <= 0.05 and pval >= 0.01:\n",
    "        ax.set_title(met + ' *')\n",
    "    elif pval <= 0.01 and pval >= 0.001:\n",
    "        ax.set_title(met + ' **')\n",
    "    elif pval <= 0.001:\n",
    "        ax.set_title(met + ' ***')\n",
    "    else:\n",
    "        ax.set_title(met)\n",
    "        \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "metrics = ['hurst', 'fisher', 'higushi']\n",
    "fig, ax = plt.subplots(1, len(metrics), figsize=(5*(len(metrics)),5))\n",
    "cond_names = ['Wake', 'Sleep']\n",
    "for i, met in enumerate(metrics):\n",
    "    # I'd love to keep only the first Y label but no idea how\n",
    "    comp_wake, comp_sleep, pval,_ = compute_A_vs_B(ep_wake, ep_sleep, met)\n",
    "    plot_A_vs_B(comp_wake, comp_sleep, cond_names, pval, met, ax=ax[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ok, so these metrics seem to be discriminant\n",
    "\n",
    "But how do they behave when computed in pseudo-realtime ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries_rs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### WITH MY OWN DATA =D\n",
    "\n",
    "alpha_rs = get_hilbert(timeseries_rs, freq=0)\n",
    "alpha_task = get_hilbert(timeseries_task, freq=0)\n",
    "\n",
    "\n",
    "metrics = ['hurst', 'svd', 'dfa' ,'higushi']\n",
    "cond_names = ['Rest', 'Task']\n",
    "fig, ax = plt.subplots(1, len(metrics), figsize=(5*(len(metrics)),5))\n",
    "\n",
    "for i, met in enumerate(metrics):\n",
    "    # I'd love to keep only the first Y label but no idea how\n",
    "    comp_rs, comp_task, pval,_ = compute_A_vs_B(alpha_rs, alpha_task, compute=met)\n",
    "    plot_A_vs_B(comp_rs, comp_task, cond_names, pval, met, ax=ax[i])\n",
    "    \n",
    "plt.savefig('complexity_Task_v_Rest_theta_avgAllch.png', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "metrics = ['hurst', 'svd' ,'higushi']\n",
    "cond_names = ['Rest', 'Task']\n",
    "fig, ax = plt.subplots(1, len(metrics), figsize=(5*(len(metrics)),5))\n",
    "\n",
    "for i, met in enumerate(metrics):\n",
    "    # I'd love to keep only the first Y label but no idea how\n",
    "    comp_rs, comp_task, pval,_ = compute_A_vs_B(timeseries_rs, timeseries_task, compute=met)\n",
    "    plot_A_vs_B(comp_rs, comp_task, cond_names, pval, met, ax=ax[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should I use EEG raw time series or power band envelopes ?\n",
    "\n",
    "# What is the window size I want to use ?\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### DEPENDING ON WINDOW SIZE AND STEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### I want a plot that shows computation times for the different metrics, depending on n_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### I want a plot that shows timecourse of different metrics over time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### I want a plot that shows timecourse of different metrics over time OVER the night, \n",
    "  # if possible applied over the hypnogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What am I going to plot ???\n",
    "# I want an interactive plot that shows the effect of adding +- of noise to the signal, \n",
    "# and check the changes on complexity measures.\n",
    "# Barplot of the differents comp measures (Hurst, DFA, SVDE, SpectralE)\n",
    "\n",
    "\n",
    "### I want to compare Higuchi, Hurst and DFA between sleep and wake\n",
    "#- DONE\n",
    "\n",
    "### I want to compare HHD "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "electrophy",
   "language": "python",
   "name": "electrophy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
